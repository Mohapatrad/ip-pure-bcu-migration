{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2cb9d94-ec13-4f6b-a34b-56e830edeaaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESEARCH_OUTPUTS_NS = 'v1.publication-import.base-uk.pure.atira.dk'\n",
    "COMMONS_NS = 'v3.commons.pure.atira.dk'\n",
    "RO_NS = \"{%s}\" % RESEARCH_OUTPUTS_NS\n",
    "C_NS = \"{%s}\" % COMMONS_NS\n",
    "NSMAP = {\"ro\": RESEARCH_OUTPUTS_NS, \"comm\": COMMONS_NS}\n",
    "\n",
    "DEFAULT_PEER_REVIEW_VALUE = 'false'\n",
    "FOR_APPROVAL_WORKFLOW_STATUS = 'forApproval'\n",
    "DEFAULT_WORKFLOW_STATUS = 'approved'\n",
    "DEFAULT_PUBLICATION_STATUS = 'published'\n",
    "DEFAULT_MANAGING_ORG_UNIT = '1'\n",
    "DEFAULT_DOCUMENT_VERSION = 'publishersversion'\n",
    "DEFAULT_DOCUMENT_ACCESS = 'unknown'\n",
    "DEFAULT_VISIBILITY = 'Public'\n",
    "DEFAULT_JOURNAL_WORKFLOW_STATUS = 'approved'\n",
    "DEFAULT_PUBLISHER_WORKFLOW_STATUS = 'approved'\n",
    "JACS_LOGICAL_NAME = 'JACSSubjectClassifications'\n",
    "ISSN_REGEX = '(\\d{4}-?\\d{3}(?:\\d|[xX]))(?: \\(([pP]rint|[oO]nline)\\))?'\n",
    "\n",
    "SUBTYPE_MAP = {'thesis': 'other',\n",
    "'article': 'article',\n",
    "'exhibition': 'exhibition' ,\n",
    "'patent': 'patent',\n",
    "'other': 'other' ,\n",
    "'artefact': 'artefact' , \n",
    "'conference_item': 'paper' ,\n",
    "'dataset': 'other',\n",
    "'composition': 'composition',\n",
    "'book': 'book', \n",
    "'book_section': 'chapter',\n",
    "'image': 'digitalorvisualproducts',\n",
    "'video': 'digitalorvisualproducts',\n",
    "'performance': 'performance',\n",
    "'monograph':'other',\n",
    "'audio':'digitalorvisualproducts'}\n",
    "\n",
    "THESIS_SUBTYPE_MAP = {'mphil': 'master', 'phd': 'doc'}\n",
    "\n",
    "PUB_STATUS_MAP = {'submitted': 'submitted', 'accepted': 'inpress', 'inpress': 'inpress', 'published_online': 'epub', \n",
    "                  'published': 'published', 'pub': 'published', 'completed': 'published', 'in_prep': 'inprep', 'unpub': 'unpublished'}\n",
    "             \n",
    "EVENT_MAP =  {'conference': 'conference', 'other': 'other' , 'workshop': 'workshop'}\n",
    "\n",
    "MEDIA_MAP =  {'online': 'online', 'cd': 'cd' , 'dvd': 'dvd', 'film': 'film' ,'exhibition':'other','performance':'other', 'other':'other'}\n",
    "\n",
    "VERSION_MAP  = {'other': 'other', 'draft': 'preprint','supplemental': 'other', 'published': 'publishersversion',\n",
    "                'accepted': 'authorsversion', 'submitted': 'preprint' }\n",
    "\n",
    "#LICENCE_MAP  = {'cc_by_nc_nd_4': 'cc_by_nc_nd_4', 'cc_by_4': 'cc_by_4','arr': 'arr', 'cc_by_nc_nd': 'cc_by_nc_nd','cc_by_nd': 'cc_by_nd',\n",
    "#                'cc_by_nd_4': 'cc_by_nd_4' }\n",
    "\n",
    "VISIBILITY_MAP = {'show': 'Public'}\n",
    "\n",
    "PERMISSION_MAP = {'public': 'open', 'staffonly': 'embargoed'}\n",
    "\n",
    "LANG_MAP = {'en': 'en_GB', 'fr': 'fr_FR', \n",
    "            'de': 'de_DE', 'ru': 'ru_RU',\n",
    "            'zh': 'zh_CN', \n",
    "            'ja': 'ja_JP', 'it': 'it_IT',\n",
    "            'nl': 'nl_NL', 'pt': 'pt_PT',\n",
    "            'pl': 'pl_PL', 'cs': 'cs_CZ',\n",
    "            'ko': 'ko_KR', 'id': 'id_ID',\n",
    "            'vi': 'vi_VN', 'es': 'es_ES',\n",
    "            'el': 'el_GR', 'fa': 'fa_IR',\n",
    "            'fi': 'fi_FI', 'aus': 'en_GB',\n",
    "            'bi': 'bi_VU', 'sk': 'sk_SK',\n",
    "            'is': 'is_IS', 'sv': 'sv_SE',\n",
    "            'other': 'und'}\n",
    "\n",
    "MONTH_MAP = {'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04', 'may': '05', 'jun': '06', 'jul': '07', 'aug': '08', 'sep': '09', 'oct': '10', 'nov': '11', 'dec': '12'}\n",
    "\n",
    "DEFAULT_LANGUAGE = 'en_GB'\n",
    "\n",
    "XML_HEADER = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n' +\\\n",
    "             '<ro:publications xmlns:ro=\"v1.publication-import.base-uk.pure.atira.dk\" xmlns:comm=\"v3.commons.pure.atira.dk\">'\n",
    "XML_FOOTER = '</ro:publications>'\n",
    "\n",
    "DIVISIONS = {\"rc1\":\"(The) Helen Hamlyn Centre for Design\"\n",
    ",\"rc2\":\"Intelligent Mobility Design Centre\"\n",
    ",\"rc3\":\"Material Science Research Centre\"\n",
    ",\"s1\":\"School of Architecture\"\n",
    ",\"ri\":\"Research & Knowledge Exchange Office\"\n",
    ",\"s7\":\"School of Arts and Humanities\"\n",
    ",\"s2\":\"School of Communication\"\n",
    ",\"rc\":\"Research Centres\"\n",
    ",\"s3\":\"School of Design\"\n",
    ",\"rc4\":\"Computer Science\"\n",
    ",\"other_sch\":\"Research & Knowledge Exchange Office\"}\n",
    "\n",
    "PRETTY_PRINT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c857efe1-f351-45eb-9e54-41a282ef456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_NSMAP = {'ep': 'http://eprints.org/ep2/data/2.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68ccd3c-dcfb-40f8-a840-d7754dc43f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lxml import etree as et\n",
    "import urllib\n",
    "def escape_entities(text):\n",
    "    escaped_text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\\\n",
    "    .replace('\"', '&quot;').replace('\\'', '&apos;')\n",
    "    return escaped_text\n",
    "\n",
    "def fit_string(source, length):\n",
    "    if len(source) > length:\n",
    "        logging.warning('String value {} longer than max size: {}. Shortening it'.format(source, length))\n",
    "        return source[:length - 3] + '...'\n",
    "    else:\n",
    "        return source\n",
    "\n",
    "def marshal_xml(tree):\n",
    "    xml_out = et.tostring(tree, pretty_print=PRETTY_PRINT, encoding=\"UTF-8\").decode(\"UTF-8\")\n",
    "    return xml_out.replace('xmlns:ro=\"{}\" '.format(RESEARCH_OUTPUTS_NS), '').replace('xmlns:comm=\"{}\" '.format(COMMONS_NS), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e834f3c-651f-4fa5-9b2f-3c6231ea408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(id, content_type, xml_in):\n",
    "    tree = et.fromstring(xml_in)\n",
    "    logging.info('Mapping publication {} with type {}'.format(id, content_type))\n",
    "    logging.info(f\"Mapping publication {id} with type {content_type}\")\n",
    "    mapping_function = MAPPING_FUNCTIONS.get(content_type)\n",
    "    if not mapping_function:\n",
    "        raise Exception('No mapping function available for content type {}'.format(content_type))\n",
    "    result = mapping_function(id, content_type, tree)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73422d9a-4a6f-4070-b291-e3267002af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_person(p):\n",
    "    result = None\n",
    "    logging.debug(p)\n",
    "    # sql_id_match = \"select id, org_id from v_persons_matching where identifiers like '%{}%' or lower(email) = '{}'\"\n",
    "    sql_name_match = 'select id, org_id from v_persons_matching where lower(family_name) = lower(%s) and lower(given_name) = lower(%s)'\n",
    "    cur1 = conn.cursor()\n",
    "    if p.get('id') is not None:\n",
    "        logging.info('Attempting match by id with {}'.format(p['id']))\n",
    "        if '\\'' in p['id']:\n",
    "            p['id'] = p['id'].replace('\\'', '\\'\\'')\n",
    "            \n",
    "        sql_id_match = f\"\"\"select id, org_id from v_persons_matching where identifiers like '%{p['id']}%' or lower(email) = '{p['id']}' \"\"\"\n",
    "        logging.info(sql_id_match)\n",
    "        cur1.execute(sql_id_match)\n",
    "        res = cur1.fetchall()\n",
    "        if len(res) == 0:\n",
    "            logging.warning('Author id {} not matched. Attempting match by name'.format(p['id']))\n",
    "            cur1.execute(sql_name_match, (p['family'], p['given']))\n",
    "            res = cur1.fetchall()\n",
    "    else:\n",
    "        logging.info('Attempting match by name with {} {}'.format(p['family'], p['given']))\n",
    "        cur1.execute(sql_name_match, (p['family'], p['given']))\n",
    "        res = cur1.fetchall()\n",
    "    if len(res) == 0:\n",
    "        logging.warning('Unable to match author {} {}. It will be treated as external'.format(p['given'], p['family']))\n",
    "    elif len(res) > 1:\n",
    "        logging.error('Multiple matches for author {} {}.'.format(p['given'], p['family']))\n",
    "    else:\n",
    "        result = res[0]\n",
    "    return result\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1479d51f-3eed-408a-9aee-c79d3043d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_author = []\n",
    "def set_persons(pub, meta):\n",
    "    owner = None\n",
    "    logging.debug('{}\\tSetting persons'.format(id))\n",
    "    # Get source data\n",
    "    source_authors = [{'family': c.find('ep:name/ep:family', EP_NSMAP).text, \n",
    "                       'given': c.find('ep:name/ep:given', EP_NSMAP).text if c.find('ep:name/ep:given', EP_NSMAP) is not None else '', \n",
    "                       'id': c.find('ep:id', EP_NSMAP).text if c.find('ep:id', EP_NSMAP) is not None else None } \n",
    "                      for c in meta.findall('ep:creators/ep:item', EP_NSMAP)]\n",
    "    source_contributors = [{'family': c.find('ep:name/ep:family', EP_NSMAP).text if c.find('ep:name/ep:family', EP_NSMAP) is not None else '', \n",
    "                       'given': c.find('ep:name/ep:given', EP_NSMAP).text if c.find('ep:name/ep:given', EP_NSMAP) is not None else '', \n",
    "                       'type_con': c.find('ep:type', EP_NSMAP).text[-3:].lower() if c.find('ep:type', EP_NSMAP) is not None else 'oth',\n",
    "                        'id':c.find('ep:id',EP_NSMAP).text if c.find('ep:id', EP_NSMAP) is not None else None} \n",
    "                      for c in meta.findall('ep:contributors/ep:item', EP_NSMAP)]\n",
    "    source_editors = [{'family': c.find('ep:name/ep:family', EP_NSMAP).text, \n",
    "                       'given': c.find('ep:name/ep:given', EP_NSMAP).text if c.find('ep:name/ep:given', EP_NSMAP) is not None else '', \n",
    "                       'id': c.find('ep:id', EP_NSMAP).text if c.find('ep:id', EP_NSMAP) is not None else None } \n",
    "                      for c in meta.findall('ep:editors/ep:item', EP_NSMAP)]\n",
    "    # Persons\n",
    "    persons = et.SubElement(pub, RO_NS+'persons', nsmap=NSMAP)\n",
    "    for p in source_authors:\n",
    "        author = et.SubElement(persons, RO_NS+'author', nsmap=NSMAP)\n",
    "        # TODO: change role\n",
    "        et.SubElement(author, RO_NS+'role', nsmap=NSMAP).text = 'author'\n",
    "        person = et.SubElement(author, RO_NS+'person', nsmap=NSMAP)\n",
    "        et.SubElement(person, RO_NS+'firstName', nsmap=NSMAP).text = p['given']\n",
    "        et.SubElement(person, RO_NS+'lastName', nsmap=NSMAP).text = p['family']\n",
    "        \n",
    "        # If internal, add the ID\n",
    "        internal_person = match_person(p)\n",
    "        if internal_person is not None:\n",
    "            logging.info('Internal person matched: {}'.format(internal_person[0]))\n",
    "            person.set('id', internal_person[0])\n",
    "            person.set('origin', 'internal')\n",
    "        else:\n",
    "            person.set('origin', 'external')\n",
    "            external_person = [(p['given']+ ' '+p['family']).title(),p['id'],DIVISIONS.get(meta.find('ep:divisions/ep:item',EP_NSMAP))]\n",
    "            if external_person not in external_author:\n",
    "                external_author.append(external_person)\n",
    "        # Person organization\n",
    "        # if author is internal, get affiliation from Pure\n",
    "        if person.get('origin') == 'internal' and internal_person[1] is not None:\n",
    "            orgs = et.SubElement(author, RO_NS+'organisations', nsmap=NSMAP)\n",
    "            org = et.SubElement(orgs, RO_NS+'organisation', nsmap=NSMAP)\n",
    "            org.set('id', internal_person[1])\n",
    "            # If this is the first internal organization encountered, set it as the owner\n",
    "            if not owner:\n",
    "                owner = internal_person[1]\n",
    "    for p in source_contributors:\n",
    "        author = et.SubElement(persons, RO_NS+'author', nsmap=NSMAP)\n",
    "        # TODO: change role\n",
    "        \n",
    "        et.SubElement(author, RO_NS+'role', nsmap=NSMAP).text = p['type_con']\n",
    "        person = et.SubElement(author, RO_NS+'person', nsmap=NSMAP)\n",
    "        et.SubElement(person, RO_NS+'firstName', nsmap=NSMAP).text = p['given']\n",
    "        et.SubElement(person, RO_NS+'lastName', nsmap=NSMAP).text = p['family']\n",
    "        internal_person = match_person(p)\n",
    "        if internal_person is not None:\n",
    "            logging.info('Internal person matched: {}'.format(internal_person[0]))\n",
    "            person.set('id', internal_person[0])\n",
    "            person.set('origin', 'internal')\n",
    "        else:\n",
    "            person.set('origin', 'external')\n",
    "            external_person = [(p['given']+ ' '+p['family']).title(),p['id'],DIVISIONS.get(meta.find('ep:divisions/ep:item',EP_NSMAP))]\n",
    "            if external_person not in external_author:\n",
    "                external_author.append(external_person)\n",
    "        if person.get('origin') == 'internal' and internal_person[1] is not None:\n",
    "            orgs = et.SubElement(author, RO_NS+'organisations', nsmap=NSMAP)\n",
    "            org = et.SubElement(orgs, RO_NS+'organisation', nsmap=NSMAP)\n",
    "            org.set('id', internal_person[1])\n",
    "    for p in source_editors:\n",
    "        author = et.SubElement(persons, RO_NS+'author', nsmap=NSMAP)\n",
    "        # TODO: change role\n",
    "        et.SubElement(author, RO_NS+'role', nsmap=NSMAP).text = 'editor'\n",
    "        person = et.SubElement(author, RO_NS+'person', nsmap=NSMAP)\n",
    "        et.SubElement(person, RO_NS+'firstName', nsmap=NSMAP).text = p['given']\n",
    "        et.SubElement(person, RO_NS+'lastName', nsmap=NSMAP).text = p['family']\n",
    "        internal_person = match_person(p)\n",
    "        if internal_person is not None:\n",
    "            logging.info('Internal person matched: {}'.format(internal_person[0]))\n",
    "            person.set('id', internal_person[0])\n",
    "            person.set('origin', 'internal')\n",
    "        else:\n",
    "            person.set('origin', 'external')\n",
    "            external_person = [(p['given']+ ' '+p['family']).title(),p['id'],DIVISIONS.get(meta.find('ep:divisions/ep:item',EP_NSMAP))]\n",
    "            if external_person not in external_author:\n",
    "                external_author.append(external_person)\n",
    "        if person.get('origin') == 'internal' and internal_person[1] is not None:\n",
    "            orgs = et.SubElement(author, RO_NS+'organisations', nsmap=NSMAP)\n",
    "            org = et.SubElement(orgs, RO_NS+'organisation', nsmap=NSMAP)\n",
    "            org.set('id', internal_person[1])\n",
    "            # If this is the first internal organization encountered, set it as the owner\n",
    "            if not owner:\n",
    "                owner = internal_person[1]\n",
    "    return owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495565c2-af10-4b58-b55a-acf8bf155d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def set_basic_metadata(pub, id, type, meta):\n",
    "    logging.debug('{} - Setting basic metadata'.format(id))\n",
    "    ## ATTRIBUTES\n",
    "    # ID\n",
    "    pub.set('id', id)\n",
    "    # Subtype\n",
    "    subtype = SUBTYPE_MAP.get(type)\n",
    "    if not subtype:\n",
    "        raise Exception('Unknown Pure subtype for {}'.format(type))\n",
    "    pub.set('subType', subtype)\n",
    "    \n",
    "    # Peer reviewed\n",
    "    pr_value =  meta.find('ep:refereed', EP_NSMAP).text.lower() if meta.find('ep:refereed', EP_NSMAP) is not None else DEFAULT_PEER_REVIEW_VALUE\n",
    "    et.SubElement(pub, RO_NS+'peerReviewed', nsmap=NSMAP).text = pr_value\n",
    "    \n",
    "    # International peer reviewed\n",
    "    # N/A\n",
    "    \n",
    "    # Accepted duplicate\n",
    "    # N/A\n",
    "    \n",
    "    # Publication category\n",
    "    #et.SubElement(pub, RO_NS+'publicationCategory', nsmap=NSMAP).text = CATEGORY_MAP.get(metadata.get('local.output.category')[0]['value'], 'unknown')\n",
    "    #print(publicationCategory.text)\n",
    "    \n",
    "    # Publication Statuses\n",
    "    pub_statuses = et.SubElement(pub, RO_NS+'publicationStatuses', nsmap=NSMAP)\n",
    "    statuses = meta.findall('ep:dates/ep:item', EP_NSMAP)\n",
    "    status_map = dict()\n",
    "    for st in statuses:\n",
    "        date_value = st.find('ep:date', EP_NSMAP).text\n",
    "        status_value_node = st.find('ep:date_type', EP_NSMAP)\n",
    "        if status_value_node is None:\n",
    "            status_value_node = meta.find('ep:ispublished', EP_NSMAP)\n",
    "        status_value = DEFAULT_PUBLICATION_STATUS if status_value_node is None else status_value_node.text\n",
    "        # Status type\n",
    "        status = PUB_STATUS_MAP.get(status_value)\n",
    "        logging.debug('Status: {}'.format(status))\n",
    "        if not status:\n",
    "            raise Exception('Unknown publication status {}'.format(status_value))\n",
    "        if status_map.get(status) is None:\n",
    "            status_map[status] = date_value\n",
    "        # If the status is already included, update the date the the greater value\n",
    "        else:\n",
    "            if date_value > status_map[status]:\n",
    "                status_map[status] = date_value\n",
    "    for s in status_map.keys():\n",
    "        pub_status = et.SubElement(pub_statuses, RO_NS+'publicationStatus', nsmap=NSMAP)\n",
    "        et.SubElement(pub_status, RO_NS+'statusType', nsmap=NSMAP).text = s\n",
    "        # Status date\n",
    "        date = et.SubElement(pub_status, RO_NS+'date', nsmap=NSMAP)\n",
    "        date_value = status_map[s].split('-')\n",
    "        et.SubElement(date, C_NS+'year', nsmap=NSMAP).text = date_value[0]\n",
    "        if len(date_value) > 1:\n",
    "            et.SubElement(date, C_NS+'month', nsmap=NSMAP).text = date_value[1]\n",
    "        if len(date_value) == 3:\n",
    "            et.SubElement(date, C_NS+'day', nsmap=NSMAP).text = date_value[2]\n",
    "    if len(pub_statuses.getchildren()) == 0:\n",
    "        raise Exception('No publication status available')\n",
    "    \n",
    "    # Workflow\n",
    "    archived = meta.find('ep:eprint_status', EP_NSMAP).text\n",
    "    if archived == 'archive':\n",
    "        et.SubElement(pub, RO_NS+'workflow', nsmap=NSMAP).text = DEFAULT_WORKFLOW_STATUS\n",
    "    else:\n",
    "        et.SubElement(pub, RO_NS+'workflow', nsmap=NSMAP).text = FOR_APPROVAL_WORKFLOW_STATUS\n",
    "    \n",
    "    # Classified descriptions\n",
    "    # N/A\n",
    "    \n",
    "    # Language: select the most frequent language of the documents associated with this record\n",
    "    langs = meta.findall('ep:documents/ep:document/ep:language', EP_NSMAP)\n",
    "    languages = [l.text for l in langs]\n",
    "    lang_freq = {languages.count(l): l for l in languages}\n",
    "    if len(languages) > 0:\n",
    "        selected_lang = lang_freq[max(lang_freq.keys())]\n",
    "        logging.info(\"Language: {}\".format(selected_lang))\n",
    "        lang_code = LANG_MAP.get(selected_lang)\n",
    "        if lang_code is None:\n",
    "            raise Exception('Unknown language: {}'.format(selected_lang))\n",
    "    else:\n",
    "        lang_code = DEFAULT_LANGUAGE\n",
    "    et.SubElement(pub, RO_NS+'language', nsmap=NSMAP).text = lang_code\n",
    "    \n",
    "    # Title\n",
    "    logging.debug('{}\\tSetting title'.format(id))\n",
    "    title = et.SubElement(pub, RO_NS+'title', nsmap=NSMAP)\n",
    "    title_text = et.SubElement(title, C_NS+'text', nsmap=NSMAP)\n",
    "    title_value = meta.find('ep:title', EP_NSMAP).text\n",
    "    # Using publication language as the title language to avoid errors\n",
    "    title_text.set('lang', lang_code.split('_')[0])\n",
    "    # Deals with language 'unknown' that lacks country code\n",
    "    if len(lang_code.split('_')) == 2:\n",
    "        title_text.set('country', lang_code.split('_')[1])\n",
    "    title_text.text = et.CDATA(title_value)\n",
    "    \n",
    "    # SubTitle\n",
    "    # N/A\n",
    "    \n",
    "    # Abstract\n",
    "    abstract_in = meta.find('ep:abstract', EP_NSMAP)\n",
    "    if abstract_in is not None:\n",
    "        logging.debug('{}\\tSetting abstract'.format(id))\n",
    "        abstract = et.SubElement(pub, RO_NS+'abstract', nsmap=NSMAP)\n",
    "        abstract_text = et.SubElement(abstract, C_NS+'text', nsmap=NSMAP)\n",
    "        # Using publication language as the abstract language\n",
    "        abstract_text.set('lang', lang_code.split('_')[0])\n",
    "        # Deals with language 'unknown' that lacks country code\n",
    "        if len(lang_code.split('_')) == 2:\n",
    "            abstract_text.set('country', lang_code.split('_')[1])\n",
    "        abstract_text.text = et.CDATA(abstract_in.text)\n",
    "    \n",
    "    # Persons: returns the first internal org_unit id encountered, so it can be set as the owner\n",
    "    owner = set_persons(pub, meta)\n",
    "    \n",
    "    # Organisations\n",
    "    # N/A\n",
    "    \n",
    "    # Owner: this is the first internal org unit found in the publication (see set_persons())\n",
    "    # If owner is None, replace it with the default managing org unit\n",
    "    if not owner:\n",
    "        owner = DEFAULT_MANAGING_ORG_UNIT\n",
    "    logging.info('Setting owner: {}'.format(owner))\n",
    "    et.SubElement(pub, RO_NS+'owner', nsmap=NSMAP).set('id', owner)\n",
    "    \n",
    "    # Keywords\n",
    "    keywords = et.SubElement(pub, RO_NS+'keywords', nsmap=NSMAP)\n",
    "    # Free text keywords\n",
    "    keys = meta.find('ep:keywords', EP_NSMAP)\n",
    "    if keys is not None:\n",
    "        keys_value = re.split(r\"[;,]\\s*\", keys.text)\n",
    "        logging.debug('{}\\tSetting free text keywords'.format(id))\n",
    "        keys_cont = et.SubElement(keywords, C_NS+'logicalGroup', nsmap=NSMAP)\n",
    "        keys_cont.set('logicalName', 'keywordContainers')\n",
    "        sks = et.SubElement(keys_cont, C_NS+'structuredKeywords', nsmap=NSMAP)\n",
    "        sk = et.SubElement(sks, C_NS+'structuredKeyword', nsmap=NSMAP)\n",
    "        fks = et.SubElement(sk, C_NS+'freeKeywords', nsmap=NSMAP)\n",
    "        for k in keys_value:\n",
    "            fk = et.SubElement(fks, C_NS+'freeKeyword', nsmap=NSMAP)\n",
    "            text = et.SubElement(fk, C_NS+'text', nsmap=NSMAP)\n",
    "            language = DEFAULT_LANGUAGE\n",
    "            lang_codes = language.split('_')\n",
    "            text.set('lang', lang_codes[0])\n",
    "            text.set('country', lang_codes[1])\n",
    "            text.text = k\n",
    "    # JACS Subject classifications\n",
    "   # jacs_keys = meta.findall('ep:subjects/ep:item', EP_NSMAP)\n",
    "    #if jacs_keys is not None and len(jacs_keys) > 0:\n",
    "     #   jacs_values = [j.text for j in jacs_keys]\n",
    "      #  lg = et.SubElement(keywords, C_NS+'logicalGroup', nsmap=NSMAP)\n",
    "       # lg.set('logicalName', JACS_LOGICAL_NAME)\n",
    "        #sks = et.SubElement(lg, C_NS+'structuredKeywords', nsmap=NSMAP)\n",
    "        #for jv in jacs_values:\n",
    "         #   sk = et.SubElement(sks, C_NS+'structuredKeyword', nsmap=NSMAP)\n",
    "          #  sk.set('classification', '{}/{}'.format(jv[:1], jv))\n",
    "    \n",
    "    if len(keywords.getchildren()) == 0:\n",
    "        pub.remove(keywords)\n",
    "    type_licence = set() \n",
    "    #URL\n",
    "    url = meta.find('ep:official_url', EP_NSMAP)\n",
    "    if url is not None:\n",
    "        url1 = et.SubElement(pub, RO_NS+'urls', nsmap=NSMAP)\n",
    "        url2 = et.SubElement(url1, RO_NS+'url', nsmap=NSMAP)\n",
    "        et.SubElement(url2, RO_NS+'url', nsmap=NSMAP).text = url.text\n",
    "    # Electronic versions\n",
    "    documents = meta.findall('ep:documents/ep:document', EP_NSMAP)\n",
    "    if documents is not None and len(documents) > 0:\n",
    "        ev = et.SubElement(pub, RO_NS+'electronicVersions', nsmap=NSMAP)\n",
    "        logging.debug('Setting Electronic Versions')\n",
    "        for document_tag in documents:   \n",
    "            # Skip all files having type 'other'\n",
    "            if document_tag.find('./ep:format', EP_NSMAP).text == 'other':\n",
    "                continue\n",
    "            extracted_data = {}\n",
    "            evfile = et.SubElement(ev, RO_NS+'electronicVersionFile', nsmap=NSMAP)\n",
    "            for item in document_tag.iter():\n",
    "                tag = item.tag.split(\"}\")[1]\n",
    "                extracted_data[tag] = item.text\n",
    "                \n",
    "                if tag == 'file':\n",
    "                    extracted_data['file_id'] = item.attrib['id']\n",
    "                    \n",
    "            if 'content' in extracted_data.keys():\n",
    "                version = et.SubElement(evfile, RO_NS+'version', nsmap=NSMAP)\n",
    "                version.text = VERSION_MAP.get(extracted_data['content'], 'other')\n",
    "                \n",
    "            if 'license' in extracted_data.keys():                \n",
    "                licence = et.SubElement(evfile, RO_NS+'licence', nsmap=NSMAP)\n",
    "                licence.text = extracted_data['license']\n",
    "            \n",
    "            if 'security' in extracted_data.keys():  \n",
    "                publicAccess = et.SubElement(evfile, RO_NS+'publicAccess', nsmap=NSMAP)\n",
    "                publicAccess.text = PERMISSION_MAP.get(extracted_data['security'], 'unknown')\n",
    "            \n",
    "            if 'date_embargo' in extracted_data.keys():  \n",
    "                date = et.SubElement(evfile, RO_NS+'embargoEndDate', nsmap=NSMAP)\n",
    "                date.text = extracted_data['date_embargo']     \n",
    "                #print(date.text, date_embargo)\n",
    "            \n",
    "            if 'doc_title' in extracted_data.keys():    \n",
    "                title = et.SubElement(evfile, RO_NS+'title', nsmap=NSMAP)\n",
    "                title.text = extracted_data['doc_title']\n",
    "                \n",
    "            file_id = extracted_data.get('file_id', 'file1')\n",
    "            file = et.SubElement(evfile, RO_NS+'file', nsmap=NSMAP, attrib={'id': file_id})\n",
    "\n",
    "            if 'filename' in extracted_data.keys():\n",
    "                filename = et.SubElement(file, RO_NS+'filename', nsmap=NSMAP)\n",
    "                filename.text = extracted_data['filename']\n",
    "\n",
    "            if 'url' in extracted_data.keys():\n",
    "                filelocation = et.SubElement(file, RO_NS+'fileLocation', nsmap=NSMAP)\n",
    "                filelocation.text = extracted_data['url']\n",
    "            \n",
    "            if 'mime_type' in extracted_data.keys():\n",
    "                mimetype = et.SubElement(file, RO_NS+'mimetype', nsmap=NSMAP)\n",
    "                mimetype.text = extracted_data['mime_type']\n",
    "            \n",
    "            if 'filesize' in extracted_data.keys():\n",
    "                filesize = et.SubElement(file, RO_NS+'filesize', nsmap=NSMAP)\n",
    "                filesize.text = extracted_data['filesize']\n",
    "            \n",
    "            if 'mtime' in extracted_data.keys():\n",
    "                depositdate = et.SubElement(file, RO_NS+'depositDate', nsmap=NSMAP)\n",
    "                depositdate.text = '-'.join(extracted_data['mtime'].split()[0].split('-')[::-1])\n",
    "            \n",
    "            source = et.SubElement(file, RO_NS+'source', nsmap=NSMAP)\n",
    "            source.text = 'EPrints'\n",
    "                \n",
    "            externalRepositoryState = et.SubElement(file, RO_NS+'externalRepositoryState', nsmap=NSMAP)\n",
    "            externalRepositoryState.text = 'STORED'\n",
    "    \n",
    "     # Remove node if no electronic versions\n",
    "        if len(ev.getchildren()) == 0:\n",
    "            pub.remove(ev)        \n",
    "    # Additional Files\n",
    "    # N/A\n",
    "    \n",
    "    # Storage\n",
    "    exs = et.SubElement(pub, RO_NS+'existingStores', nsmap=NSMAP)\n",
    "    ex =  et.SubElement(exs, RO_NS+'existingStore', nsmap=NSMAP)\n",
    "    et.SubElement(ex, RO_NS+'storeName', nsmap=NSMAP).text = 'BCU ePrints'\n",
    "    eid = meta.find('ep:eprintid', EP_NSMAP)\n",
    "    if eid is not None:\n",
    "        et.SubElement(ex, RO_NS+'storeContentId', nsmap=NSMAP).text = eid.text\n",
    "    \n",
    "    # Transfer to repository: set to FALSE (these are already in the repository\n",
    "    et.SubElement(pub, RO_NS+'transferToRepository', nsmap=NSMAP).text = 'false'\n",
    "    \n",
    "    # Bibliographical Notes\n",
    "    if meta.find('ep:funders', EP_NSMAP) is not None:\n",
    "        bib_notes = et.SubElement(pub, RO_NS+'bibliographicalNotes', nsmap=NSMAP)\n",
    "        text = '<br/>'.join([f.text for f in meta.findall('ep:funders/ep:item', EP_NSMAP)])\n",
    "        logging.info('Setting bibliographical note')\n",
    "        bib_note = et.SubElement(bib_notes, RO_NS+'bibliographicalNote', nsmap=NSMAP)\n",
    "        note_text = et.SubElement(bib_note, C_NS+'text', nsmap=NSMAP)\n",
    "        language = DEFAULT_LANGUAGE\n",
    "        lang_codes = language.split('_')\n",
    "        note_text.set('lang', lang_codes[0])\n",
    "        note_text.set('country', lang_codes[1])\n",
    "        note_text.text = text\n",
    "    \n",
    "    # Visibility\n",
    "    visibility = meta.find('ep:metadata_visibility', EP_NSMAP)\n",
    "    value = DEFAULT_VISIBILITY\n",
    "    if visibility is not None:\n",
    "        value = VISIBILITY_MAP[visibility.text]\n",
    "        et.SubElement(pub, RO_NS+'visibility', nsmap=NSMAP).text = value\n",
    "    \n",
    "    # External IDs\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8215c2-71be-41cd-91af-e3af4c35f458",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def map_article(id, type, meta):\n",
    "    logging.info('Mapping publication {} to journal article'.format(id))\n",
    "    pub = et.Element(RO_NS+'contributionToJournal', nsmap=NSMAP)\n",
    "    # Basic metadata\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    \n",
    "    # Pages\n",
    "    page_range = meta.find('ep:pagerange', EP_NSMAP)\n",
    "    if page_range is not None:\n",
    "        et.SubElement(pub, RO_NS+'pages', nsmap=NSMAP).text = page_range.text\n",
    "    \n",
    "    # Page number\n",
    "    page_num = meta.find('ep:pages', EP_NSMAP)\n",
    "    if page_num is not None:\n",
    "        et.SubElement(pub, RO_NS+'numberOfPages', nsmap=NSMAP).text = page_num.text\n",
    "    \n",
    "    # Article Number\n",
    "    # N/A\n",
    "    \n",
    "    # Journal number\n",
    "    issue = meta.find('ep:number', EP_NSMAP)\n",
    "    if issue is not None:\n",
    "        et.SubElement(pub, RO_NS+'journalNumber', nsmap=NSMAP).text = fit_string(issue.text, 64)\n",
    "    \n",
    "    # Journal volume\n",
    "    volume = meta.find('ep:volume', EP_NSMAP)\n",
    "    if volume is not None:\n",
    "        et.SubElement(pub, RO_NS+'journalVolume', nsmap=NSMAP).text = volume.text\n",
    "    \n",
    "    # Journal\n",
    "    journal = et.SubElement(pub, RO_NS+'journal', nsmap=NSMAP)\n",
    "    journaltit = meta.find('ep:publication', EP_NSMAP)\n",
    "    # Title\n",
    "    if journaltit is not None:\n",
    "        et.SubElement(journal, RO_NS+'title', nsmap=NSMAP).text = journaltit.text\n",
    "    # ISSN. By default ISSN is considered print if not specified\n",
    "    issn = meta.find('ep:issn', EP_NSMAP)\n",
    "    if issn is not None:\n",
    "        pissns = et.SubElement(journal, RO_NS+'printIssns', nsmap=NSMAP)\n",
    "        eissns = et.SubElement(journal, RO_NS+'electronicIssns', nsmap=NSMAP)\n",
    "        regex = re.compile(ISSN_REGEX)\n",
    "        results = regex.findall(issn.text)\n",
    "        if len(results) == 0:\n",
    "            logging.warning('Unknown ISSN format: {}'.format(issn.text))\n",
    "        logging.debug('Parsed issns: {}'.format(results))\n",
    "        for r in results:\n",
    "            if r[1] == 'Print' or r[1] == '':\n",
    "                et.SubElement(pissns, RO_NS+'issn', nsmap=NSMAP).text = r[0]\n",
    "            else:\n",
    "                et.SubElement(eissns, RO_NS+'issn', nsmap=NSMAP).text = r[0]\n",
    "        if len(pissns.getchildren()) == 0:\n",
    "            journal.remove(pissns)\n",
    "        if len(eissns.getchildren()) == 0:\n",
    "            journal.remove(eissns)\n",
    "    # Publisher\n",
    "    publisher = meta.find('ep:publisher', EP_NSMAP)\n",
    "    if publisher is not None:\n",
    "        publishers = et.SubElement(journal, RO_NS+'publisher', nsmap=NSMAP)\n",
    "        #name\n",
    "        et.SubElement(publishers, RO_NS+'name', nsmap=NSMAP).text = publisher.text\n",
    "        et.SubElement(publishers, RO_NS+'workflow', nsmap=NSMAP).text = DEFAULT_PUBLISHER_WORKFLOW_STATUS\n",
    "    #workflow\n",
    "    et.SubElement(journal, RO_NS+'workflow', nsmap=NSMAP).text = DEFAULT_JOURNAL_WORKFLOW_STATUS\n",
    "    # Event\n",
    "    # N/A\n",
    "    \n",
    "    # Case notes\n",
    "    # N/A\n",
    "    \n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60bd002f-a5b1-4c96-be63-52642af24454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_chapter(id, type, meta):\n",
    "    logging.info('Mapping publication {} to book chapter'.format(id))\n",
    "    pub = et.Element(RO_NS+'chapterInBook', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    # pages\n",
    "    page_range = meta.find('ep:pagerange', EP_NSMAP)\n",
    "    if page_range is not None:\n",
    "        et.SubElement(pub, RO_NS+'pages', nsmap=NSMAP).text = page_range.text\n",
    "    # numberOfPages\n",
    "    page_num = meta.find('ep:pages', EP_NSMAP)\n",
    "    if page_num is not None:\n",
    "        et.SubElement(pub, RO_NS+'numberOfPages', nsmap=NSMAP).text = page_num.text\n",
    "    # chapter\n",
    "    # N/A\n",
    "    # articleNumber \n",
    "    an = meta.find('ep:number', EP_NSMAP)\n",
    "    if an is not None:\n",
    "        et.SubElement(pub, RO_NS+'articleNumber', nsmap=NSMAP).text = an.text\n",
    "    # edition\n",
    "    # N/A\n",
    "    # placeOfPublication\n",
    "    place_of_pub = meta.find('ep:place_of_pub', EP_NSMAP)\n",
    "    if place_of_pub is not None:\n",
    "        et.SubElement(pub, RO_NS+'placeOfPublication', nsmap=NSMAP).text = place_of_pub.text\n",
    "    # volume\n",
    "    volume = meta.find('ep:volume', EP_NSMAP)\n",
    "    if volume is not None:\n",
    "        et.SubElement(pub, RO_NS+'volume', nsmap=NSMAP).text = volume.text    \n",
    "     # printIsbns\n",
    "    keys = meta.find('ep:isbn', EP_NSMAP)\n",
    "    if keys is not None:\n",
    "        if len(keys.text) >= 20:\n",
    "            logging.warning('Suspect ISBN value for publication {}: {}'.format(id, keys.text))\n",
    "        keys_value = keys.text.split('; ')\n",
    "        keys_cont = et.SubElement(pub, RO_NS+'printIsbns', nsmap=NSMAP)\n",
    "        for k in keys_value:\n",
    "            et.SubElement(keys_cont, RO_NS+'isbn', nsmap=NSMAP).text = k\n",
    "    # electronicIsbns\n",
    "    # N/A\n",
    "    # hostPublicationTitle - To be reviewed with customer\n",
    "    hostpubtitle = meta.find('ep:title', EP_NSMAP)\n",
    "    if hostpubtitle is not None:\n",
    "        et.SubElement(pub, RO_NS+'hostPublicationTitle', nsmap=NSMAP).text = hostpubtitle.text\n",
    "    # hostPublicationsubTitle\n",
    "    # N/A\n",
    "    # publisher\n",
    "    publisher = meta.find('ep:publisher', EP_NSMAP)\n",
    "    if publisher is not None:\n",
    "        publishers = et.SubElement(pub, RO_NS+'publisher', nsmap=NSMAP)\n",
    "        # name\n",
    "        et.SubElement(publishers, RO_NS+'name', nsmap=NSMAP).text = publisher.text\n",
    "        et.SubElement(publishers, RO_NS+'workflow', nsmap=NSMAP).text = DEFAULT_PUBLISHER_WORKFLOW_STATUS\n",
    "    # editors\n",
    "    editorsin = meta.find('ep:editors', EP_NSMAP)\n",
    "    if editorsin is not None:\n",
    "        names = editorsin.findall('ep:item/ep:name', EP_NSMAP)\n",
    "        editors = et.SubElement(pub, RO_NS+'editors', nsmap=NSMAP)\n",
    "        for n in names:\n",
    "            editor = et.SubElement(editors, RO_NS+'editor', nsmap=NSMAP)\n",
    "            et.SubElement(editor, C_NS+'firstname', nsmap=NSMAP).text = n.find('ep:given', EP_NSMAP).text\n",
    "            et.SubElement(editor, C_NS+'lastname', nsmap=NSMAP).text = n.find('ep:family', EP_NSMAP).text\n",
    "    # series\n",
    "    seriesin = meta.find('ep:series', EP_NSMAP)\n",
    "    if seriesin is not None:\n",
    "        series = et.SubElement(pub, RO_NS+'series', nsmap=NSMAP)\n",
    "        serie = et.SubElement(series, RO_NS+'serie', nsmap=NSMAP)\n",
    "        et.SubElement(serie, RO_NS+'name', nsmap=NSMAP).text = seriesin.text\n",
    "    # event\n",
    "     # N/A\n",
    "    # caseNotes\n",
    "    # N/A\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2423b8d9-9c10-4e18-baa4-29fbefcf7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_book(id, type, meta):\n",
    "    logging.info('Mapping publication {} to book'.format(id))\n",
    "    pub = et.Element(RO_NS+'book', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    # numberOfPages\n",
    "    page_num = meta.find('ep:pages', EP_NSMAP)\n",
    "    if page_num is not None:\n",
    "        et.SubElement(pub, RO_NS+'numberOfPages', nsmap=NSMAP).text = page_num.text\n",
    "    # placeOfPublication\n",
    "    placeOfPub = meta.find('ep:place_of_pub', EP_NSMAP)\n",
    "    if placeOfPub is not None:\n",
    "        et.SubElement(pub, RO_NS+'placeOfPublication', nsmap=NSMAP).text = placeOfPub.text\n",
    "    # edition\n",
    "    # N/A\n",
    "    # volume\n",
    "    volume = meta.find('ep:volume', EP_NSMAP)\n",
    "    if volume is not None:\n",
    "        et.SubElement(pub, RO_NS+'volume', nsmap=NSMAP).text = volume.text   \n",
    "     # printIsbns\n",
    "    keys = meta.find('ep:isbn', EP_NSMAP)\n",
    "    if keys is not None:\n",
    "        if len(keys.text) >= 20:\n",
    "            logging.warning('Suspect ISBN value for publication {}: {}'.format(id, keys.text))\n",
    "        keys_value = keys.text.split('; ')\n",
    "        keys_cont = et.SubElement(pub, RO_NS+'printIsbns', nsmap=NSMAP)\n",
    "        for k in keys_value:\n",
    "            et.SubElement(keys_cont, RO_NS+'isbn', nsmap=NSMAP).text = k\n",
    "    # electronicIsbns\n",
    "    # N/A\n",
    "    # commissioningBodyExternalOrganisation\n",
    "    # N/A\n",
    "    # series\n",
    "    seriesin = meta.find('ep:series', EP_NSMAP)\n",
    "    if seriesin is not None:\n",
    "        series = et.SubElement(pub, RO_NS+'series', nsmap=NSMAP)\n",
    "        serie = et.SubElement(series, RO_NS+'serie', nsmap=NSMAP)\n",
    "        et.SubElement(serie, RO_NS+'name', nsmap=NSMAP).text = seriesin.text\n",
    "    # publisher\n",
    "    publisher = meta.find('ep:publisher', EP_NSMAP)\n",
    "    if publisher is not None:\n",
    "        publishers = et.SubElement(pub, RO_NS+'publisher', nsmap=NSMAP)\n",
    "        # name\n",
    "        et.SubElement(publishers, RO_NS+'name', nsmap=NSMAP).text = publisher.text\n",
    "        et.SubElement(publishers, RO_NS+'workflow', nsmap=NSMAP).text = DEFAULT_PUBLISHER_WORKFLOW_STATUS\n",
    "    # event\n",
    "    # N/A\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337248d1-ba6c-494b-98c8-705e62f7e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_other(id, type, meta):\n",
    "    logging.info('Mapping publication {} to other contribution'.format(id))\n",
    "    pub = et.Element(RO_NS+'other', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    #outputMedia\n",
    "    output_media = meta.find('ep:output_media', EP_NSMAP)\n",
    "    if output_media is not None:\n",
    "        value = MEDIA_MAP.get(output_media.text.lower(),'other')\n",
    "        et.SubElement(pub, RO_NS+'outputMedia', nsmap=NSMAP).text = value\n",
    "    # numberOfPages\n",
    "    # N/A\n",
    "    # placeOfPublication\n",
    "    place_of_pub = meta.find('ep:place_of_pub', EP_NSMAP)\n",
    "    if place_of_pub is not None:\n",
    "        et.SubElement(pub, RO_NS+'placeOfPublication', nsmap=NSMAP).text = place_of_pub.text\n",
    "    # edition\n",
    "    # N/A\n",
    "    # volume\n",
    "    # N/A\n",
    "    # printIsbns\n",
    "    keys = meta.find('ep:isbn', EP_NSMAP)\n",
    "    if keys is not None:\n",
    "        if len(keys.text) >= 20:\n",
    "            logging.warning('Suspect ISBN value for publication {}: {}'.format(id, keys.text))\n",
    "        keys_value = keys.text.split('; ')\n",
    "        keys_cont = et.SubElement(pub, RO_NS+'printIsbns', nsmap=NSMAP)\n",
    "        for k in keys_value:\n",
    "            et.SubElement(keys_cont, RO_NS+'isbn', nsmap=NSMAP).text = k\n",
    "    # electronicIsbns\n",
    "    # N/A\n",
    "    # series\n",
    "    # N/A\n",
    "    # publisher\n",
    "    publisher = meta.find('ep:publisher', EP_NSMAP)\n",
    "    if publisher is not None:\n",
    "        publishers = et.SubElement(pub, RO_NS+'publisher', nsmap=NSMAP)\n",
    "        # name\n",
    "        et.SubElement(publishers, RO_NS+'name', nsmap=NSMAP).text = publisher.text\n",
    "        et.SubElement(publishers, RO_NS+'workflow', nsmap=NSMAP).text = DEFAULT_PUBLISHER_WORKFLOW_STATUS\n",
    "    # caseNotes\n",
    "    # N/A\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94547379-cfe7-428b-a00d-e81c65bfa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventdate transformations\n",
    "from datetime import date\n",
    "def double(num):\n",
    "    if len(num) == 1:\n",
    "        return '0' + num\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "def quad(year):\n",
    "    if len(year)!=4:\n",
    "        if int(year) > date.today().year%100:\n",
    "            return '19' + year\n",
    "        else:\n",
    "            return '20' + year\n",
    "    else:\n",
    "        return year\n",
    "\n",
    "def get_start_end(eventdate):\n",
    "    # Default value for start_date and end_date\n",
    "    start_date=end_date=date.today().strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    # Replace any separator or space with hyphen\n",
    "    eventdate = re.sub(r' to ','',eventdate)\n",
    "    eventdate = re.sub(r'\\W+','-',eventdate)\n",
    "    eventdate = re.sub(r\"(?<=\\d)(st|nd|rd|th)\\b\",\"\", eventdate)\n",
    "\n",
    "    # Possible regex patterns\n",
    "    patterns = [\n",
    "    r'^(\\d{1,2})-(\\d{1,2})-(\\d{2,4})-(\\d{1,2})-(\\d{1,2})-(\\d{2,4})', # Two dates num, different months, two years\n",
    "    r'^(\\d{1,2})-(\\d{1,2})-(\\d{1,2})-(\\d{1,2})-(\\d{2,4})', # Two dates num, different months, one year\n",
    "    r'^(\\d{1,2})-(\\d{1,2})-(\\d{1,2})-(\\d{2,4})', # Two Dates Num, same month\n",
    "    r'^(\\d{1,2})-(\\d{1,2})-(\\d{2,4})', # Single Date Num\n",
    "    r'^([a-zA-Z]+)-(\\d{1,2})-(\\d{2,4})', # Single Date Reverse\n",
    "    r'^(\\d{1,2})-(\\d{1,2})-([a-zA-Z.]+)-(\\d{2,4})', # Two Dates, same month\n",
    "    r'^(\\d{1,2})-([a-zA-Z.]+)-(\\d{1,2})-([a-zA-Z.]+)-(\\d{2,4})', # Two Dates, different months\n",
    "    r'^(\\d{1,2})-([a-zA-Z.]+)-(\\d{2,4})-(\\d{1,2})-([a-zA-Z.]+)-(\\d{2,4})', # Two dates, two months, two years\n",
    "    r'^([a-zA-Z.]+)-(\\d{1,2})-(\\d{1,2})-(\\d{2,4})', # Two Dates, same month, reverse\n",
    "    r'^([a-zA-Z.]+)-(\\d{1,2})-([a-zA-Z]+)-(\\d{1,2})-(\\d{2,4})', # Two Dates, different months, reverse\n",
    "    r'^(\\d{1,2})-([a-zA-Z]+)-(\\d{2,4})', # Single Date\n",
    "    ]\n",
    "    \n",
    "    # Standardization of dates\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, eventdate)\n",
    "        if match:\n",
    "            match = match.groups()\n",
    "            if all(element.isnumeric() for element in match):\n",
    "                if len(match) == 6:\n",
    "                    start_date = double(match[0]) + '-' + double(match[1]) + '-' + quad(match[2])\n",
    "                    end_date = double(match[3]) + '-' + double(match[4]) + '-' + quad(match[5])\n",
    "                    return start_date, end_date\n",
    "                elif len(match) == 5:\n",
    "                    start_date = double(match[0]) + '-' + double(match[1]) + '-' + quad(match[4])\n",
    "                    end_date = double(match[2]) + '-' + double(match[3]) + '-' + quad(match[4])\n",
    "                    return start_date, end_date\n",
    "                elif len(match) == 4:\n",
    "                    start_date = double(match[0]) + '-' + double(match[2]) + '-' + quad(match[3])\n",
    "                    end_date = double(match[1]) + '-' + double(match[2]) + '-' + quad(match[3])\n",
    "                    return start_date, end_date\n",
    "                elif len(match) == 3:\n",
    "                    start_date=end_date = double(match[0]) + '-' + double(match[1]) + '-' + quad(match[2])\n",
    "                    return start_date, end_date\n",
    "            if len(match) == 6:\n",
    "                if match[1].isalpha() and match[4].isalpha()  and match[1].lower()[:3] in MONTH_MAP.keys() and match[4].lower()[:3] in MONTH_MAP.keys():\n",
    "                    start_date = double(match[0]) + '-' + MONTH_MAP[match[1].lower()[:3]] + '-' + quad(match[2])\n",
    "                    end_date = double(match[3]) + '-' + MONTH_MAP[match[4].lower()[:3]] + '-' + quad(match[5])\n",
    "                    return start_date, end_date\n",
    "            elif len(match) == 3:\n",
    "                if match[0].isalpha() and match[0].lower()[:3] in MONTH_MAP.keys():\n",
    "                    start_date = end_date = double(match[1]) + '-' + MONTH_MAP[match[0].lower()[:3]] + '-' + quad(match[2])\n",
    "                    return start_date, end_date\n",
    "                else:\n",
    "                    start_date = end_date = double(match[0]) + '-' + MONTH_MAP[match[1].lower()[:3]] + '-' + quad(match[2])\n",
    "                    return start_date, end_date\n",
    "            elif len(match) == 4:\n",
    "                if match[2].isalpha() and match[2].lower()[:3] in MONTH_MAP.keys():\n",
    "                    start_date = double(match[0]) + '-' + MONTH_MAP[match[2].lower()[:3]] + '-' + quad(match[3])\n",
    "                    end_date = double(match[1]) + '-' + MONTH_MAP[match[2].lower()[:3]] + '-' + quad(match[3])\n",
    "                    return start_date, end_date\n",
    "                elif match[0].isalpha() and match[0].lower()[:3] in MONTH_MAP.keys():\n",
    "                    start_date = double(match[1]) + '-' + MONTH_MAP[match[0].lower()[:3]] + '-' + quad(match[3])\n",
    "                    end_date = double(match[2]) + '-' + MONTH_MAP[match[0].lower()[:3]] + '-' + quad(match[3])\n",
    "                    return start_date, end_date\n",
    "            elif len(match) == 5:\n",
    "                if match[1].isalpha() and match[3].isalpha()  and match[1].lower()[:3] in MONTH_MAP.keys() and match[3].lower()[:3] in MONTH_MAP.keys():\n",
    "                    start_date = double(match[0]) + '-' + MONTH_MAP[match[1].lower()[:3]] + '-' + quad(match[4])\n",
    "                    end_date = double(match[2]) + '-' + MONTH_MAP[match[3].lower()[:3]] + '-' + quad(match[4])\n",
    "                    return start_date, end_date\n",
    "                else:\n",
    "                    start_date = double(match[1]) + '-' + MONTH_MAP[match[0].lower()[:3]] + '-' + quad(match[4])\n",
    "                    end_date = double(match[3]) + '-' + MONTH_MAP[match[2].lower()[:3]] + '-' + quad(match[4])\n",
    "                    return start_date, end_date\n",
    "\n",
    "                \n",
    "    return start_date, end_date\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87a59dca-3431-41d1-95c2-ea1bd975c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_conference(id, type, meta):\n",
    "    logging.info('Mapping publication {} to conference'.format(id))\n",
    "    pub = et.Element(RO_NS+'contributionToConference', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    # pages\n",
    "    # N/A\n",
    "    # numberOfPages\n",
    "    # N/A\n",
    "    # Event\n",
    "    event = et.SubElement(pub, RO_NS+'event', nsmap=NSMAP)\n",
    "    eventType = meta.find('ep:event_type', EP_NSMAP)\n",
    "    if eventType is not None:\n",
    "        et.SubElement(event, RO_NS+'type', nsmap=NSMAP).text = eventType.text\n",
    "    eventTitle = meta.find('ep:event_title', EP_NSMAP)\n",
    "    if eventTitle is not None:\n",
    "        title = et.SubElement(event, RO_NS+'title', nsmap=NSMAP)\n",
    "        et.SubElement(title, C_NS+'text', nsmap=NSMAP).text = eventTitle.text\n",
    "    location = meta.find('ep:event_location', EP_NSMAP)\n",
    "    if location is not None:\n",
    "        et.SubElement(event, RO_NS+'location', nsmap=NSMAP).text = location.text\n",
    "    eventdate = meta.find('ep:event_dates', EP_NSMAP)\n",
    "    if eventdate is not None:\n",
    "        start_date, end_date = get_start_end(eventdate.text)\n",
    "        #print(id,eventdate.text, start_date, end_date)\n",
    "        et.SubElement(event, RO_NS+'startDate', nsmap=NSMAP).text = start_date\n",
    "        et.SubElement(event, RO_NS+'endDate', nsmap=NSMAP).text = end_date\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83855c9b-e2fd-4d40-8482-2dac46553020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_non_textual(id, type, meta):\n",
    "    logging.info('Mapping publication {} to non textual contribution'.format(id))\n",
    "    pub = et.Element(RO_NS+'nonTextual', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    #outputMedia\n",
    "    output_media = meta.find('ep:output_media', EP_NSMAP)\n",
    "    if output_media is not None:\n",
    "        value = MEDIA_MAP.get(output_media.text.lower(),'other')\n",
    "        et.SubElement(pub, RO_NS+'outputMedia', nsmap=NSMAP).text = value\n",
    "    # Event\n",
    "    event = et.SubElement(pub, RO_NS+'event', nsmap=NSMAP)\n",
    "    eventType = meta.find('ep:event_type', EP_NSMAP)\n",
    "    if eventType is not None:\n",
    "        et.SubElement(event, RO_NS+'type', nsmap=NSMAP).text = eventType.text\n",
    "    eventTitle = meta.find('ep:event_title', EP_NSMAP)\n",
    "    if eventTitle is not None:\n",
    "        title = et.SubElement(event, RO_NS+'title', nsmap=NSMAP)\n",
    "        et.SubElement(title, C_NS+'text', nsmap=NSMAP).text = eventTitle.text\n",
    "    location = meta.find('ep:event_location', EP_NSMAP)\n",
    "    if location is not None:\n",
    "        et.SubElement(event, RO_NS+'location', nsmap=NSMAP).text = location.text\n",
    "    eventdate = meta.find('ep:event_dates', EP_NSMAP)\n",
    "    #print(eventdate.text)\n",
    "    if eventdate is not None:\n",
    "        start_date, end_date = get_start_end(eventdate.text)\n",
    "        #print(id,eventdate.text, start_date, end_date)\n",
    "        et.SubElement(event, RO_NS+'startDate', nsmap=NSMAP).text = start_date\n",
    "        et.SubElement(event, RO_NS+'endDate', nsmap=NSMAP).text = end_date\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b60813-2006-401a-9fd2-09af44efdbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_working_paper(id, type, meta):\n",
    "    logging.info('Mapping publication {} to working paper'.format(id))\n",
    "    pub = et.Element(RO_NS+'workingPaper', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    # pages\n",
    "    pages = meta.find('ep:pagerange', EP_NSMAP)\n",
    "    if pages is not None:\n",
    "        et.SubElement(pub, RO_NS+'pages').text = pages.text\n",
    "    # numberOfPages\n",
    "    noOfpages = meta.find('ep:pages', EP_NSMAP)\n",
    "    if noOfpages is not None:\n",
    "        et.SubElement(pub, RO_NS+'numberOfPages').text = noOfpages.text\n",
    "    # placeOfPublication\n",
    "    place_of_pub = meta.find('ep:place_of_pub', EP_NSMAP)\n",
    "    if place_of_pub is not None:\n",
    "        et.SubElement(pub, RO_NS+'placeOfPublication', nsmap=NSMAP).text = place_of_pub.text\n",
    "    # volume\n",
    "    volume = meta.find('ep:volume', EP_NSMAP)\n",
    "    if volume is not None:\n",
    "        et.SubElement(pub, RO_NS+'volume').text = volume.text\n",
    "    # volume\n",
    "    edition = meta.find('ep:number', EP_NSMAP)\n",
    "    if edition is not None:\n",
    "        et.SubElement(pub, RO_NS+'edition').text = edition.text\n",
    "    # publisher\n",
    "    publisher = meta.find('ep:publisher', EP_NSMAP)\n",
    "    if publisher is not None:\n",
    "        publishers = et.SubElement(pub, RO_NS+'publisher', nsmap=NSMAP)\n",
    "        # name\n",
    "        et.SubElement(publishers, RO_NS+'name', nsmap=NSMAP).text = publisher.text\n",
    "        et.SubElement(publishers, RO_NS+'workflow', nsmap=NSMAP).text = DEFAULT_PUBLISHER_WORKFLOW_STATUS\n",
    "     # printIsbns\n",
    "    keys = meta.find('ep:isbn', EP_NSMAP)\n",
    "    if keys is not None:\n",
    "        if len(keys.text) >= 20:\n",
    "            logging.warning('Suspect ISBN value for publication {}: {}'.format(id, keys.text))\n",
    "        keys_value = keys.text.split('; ')\n",
    "        keys_cont = et.SubElement(pub, RO_NS+'printIsbns', nsmap=NSMAP)\n",
    "        for k in keys_value:\n",
    "            et.SubElement(keys_cont, RO_NS+'isbn', nsmap=NSMAP).text = k\n",
    "    # series\n",
    "    seriesin = meta.find('ep:series', EP_NSMAP)\n",
    "    if seriesin is not None:\n",
    "        series = et.SubElement(pub, RO_NS+'series', nsmap=NSMAP)\n",
    "        serie = et.SubElement(series, RO_NS+'serie', nsmap=NSMAP)\n",
    "        et.SubElement(serie, RO_NS+'name', nsmap=NSMAP).text = seriesin.text\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b9def81-75a6-4ead-b7b9-12a0f2052bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_patent(id, type, meta):\n",
    "    logging.info('Mapping publication {} to patent'.format(id))\n",
    "    pub = et.Element(RO_NS+'patent', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    # ipc\n",
    "    # N/A\n",
    "    # patentNumber\n",
    "    # N/A\n",
    "    # date\n",
    "    date_in = meta.find('ep:date', EP_NSMAP)\n",
    "    if date_in is not None:\n",
    "        et.SubElement(pub, RO_NS+'date').text = date_in.text\n",
    "    # priorityDate\n",
    "    # N/A\n",
    "    # priorityNumber\n",
    "    # N/A\n",
    "    # country\n",
    "    # N/A\n",
    "    # publisher\n",
    "    # N/A\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1dec7-6b6a-4a00-bf6d-c86a12744c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_thesis(id, type, meta):\n",
    "    logging.info('Mapping publication {} to thesis'.format(id))\n",
    "    pub = et.Element(RO_NS+'thesis', nsmap=NSMAP)\n",
    "    set_basic_metadata(pub, id, type, meta)\n",
    "    # TODO\n",
    "    #Qualification\n",
    "    qual = meta.find('ep:thesis_name', EP_NSMAP)\n",
    "    if qual is not None:\n",
    "        et.SubElement(pub, RO_NS+'qualification', nsmap=NSMAP).text = qual.text\n",
    "    thesis_subtype = THESIS_SUBTYPE_MAP.get(qual.text)\n",
    "    if thesis_subtype is None:\n",
    "        raise Exception('Unknown thesis type: {}'.format(qual.text))\n",
    "        pub.set('subType', thesis_subtype)\n",
    "    else:\n",
    "        raise Exception('Missing qualification information')\n",
    "    #Number of pages\n",
    "    pages_in = meta.find('ep:pages', EP_NSMAP)\n",
    "    if pages_in is not None:\n",
    "        et.SubElement(pub, RO_NS+'numberOfPages').text = pages_in.text\n",
    "    return marshal_xml(pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf20400e-205a-4454-9332-3b8eaa96e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING_FUNCTIONS = {'conference_item': map_conference,\n",
    "'patent': map_patent,\n",
    "'article': map_article,\n",
    "'book': map_book,\n",
    "'book_section': map_chapter, \n",
    "'exhibition': map_non_textual,\n",
    "'performance': map_non_textual,\n",
    "'composition': map_non_textual,\n",
    "'artefact': map_non_textual,\n",
    "'audio': map_non_textual,\n",
    "'video': map_non_textual,\n",
    "'image': map_non_textual,\n",
    "'monograph': map_other,\n",
    "'dataset': map_other,\n",
    "'thesis': map_thesis,\n",
    "'other': map_other}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94002046-ba25-4071-a541-26162b1b48f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
